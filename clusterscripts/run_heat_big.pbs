#!/bin/bash
# run_heat_big_auto.pbs - ASCII only

set -euo pipefail

if [ -z "${PBS_JOBID:-}" ]; then
  TOTAL=$(python3 - <<'PY'
NCELLS=[2,4,8,16,32,64,128,256,512]
DT=[1e-1,1e-2,1e-3,1e-4,1e-5]
M=list(range(1,11))
print(len(NCELLS)*len(DT)*len(M))
PY
)

  choose_queue() {
    local best="standard"
    local min=999999
    # parse qstat -Q
    while read -r q mem cput wt node run que lm state; do
      [ -z "$q" ] && continue
      [ "$q" = "Queue" ] && continue
      [ "$q" = "-----" ] && continue
      case "$q" in
        medium|jumbo|firedrake|standard)
          local load=$(( ${run:-0} + ${que:-0} ))
          if [ "$load" -lt "$min" ]; then
            min=$load; best=$q
          fi
          ;;
      esac
    done < <(qstat -Q 2>/dev/null || true)
    echo "$best"
  }

  Q=$(choose_queue)
  echo "Submitting array of $TOTAL to queue: $Q (max 64 concurrent)"

  exec qsub -q "$Q" \
    -N run_heat_big \
    -l nodes=1:ppn=1,mem=1900mb \
    -m bea -M ok24@ic.ac.uk \
    -j oe \
    -o /home/ma/o/ok24/logs/\$PBS_JOBID.log \
    -t 0-$((TOTAL-1))%64 \
    "$0"
fi

set -x
echo "[START] $(date) host=$(hostname) job=${PBS_JOBID} arr=${PBS_ARRAYID:-0} user=${USER}"

export OMP_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1 MKL_NUM_THREADS=1 \
       BLIS_NUM_THREADS=1 VECLIB_MAXIMUM_THREADS=1 NUMEXPR_NUM_THREADS=1 \
       GOTO_NUM_THREADS=1

source /usr/local/firedrake/bin/activate

export HOME=/home/ma/o/ok24
export XDG_CACHE_HOME="$HOME/.cache"
export PYOP2_CACHE_DIR="$XDG_CACHE_HOME/pyop2"
export TSFC_KERNEL_CACHE_DIR="$XDG_CACHE_HOME/tsfc"
export TSFC_CACHE_DIR="$XDG_CACHE_HOME/tsfc"
export FIREDRAKE_TSFC_KERNEL_CACHE_DIR="$XDG_CACHE_HOME/tsfc"
export PYOP2_ALWAYS_REBUILD=1
mkdir -p "$PYOP2_CACHE_DIR" "$TSFC_KERNEL_CACHE_DIR" /home/ma/o/ok24/logs

cd /home/ma/o/ok24
which python3
python3 -V

STAGE="/tmp/sdc-${USER}-${PBS_JOBID}.${PBS_ARRAYID:-0}"
DEST="/home/clustor2/ma/o/ok24/solver_results/heatfiles"
mkdir -p "$STAGE" "$DEST"
export SDC_OUTPUT_DIR="$STAGE"

python3 -u - <<'PY'
import os, json
from itertools import product
NCELLS=[2,4,8,16,32,64,128,256,512]
DT=[1e-1,1e-2,1e-3,1e-4,1e-5]
M=list(range(1,11))
TFINAL=1.0
DEGREE=1
idx = int(os.environ.get("PBS_ARRAYID","0"))
combos = list(product(NCELLS, DT, M))
n, dt, m = combos[idx]
sweeps = m
print(f"[ARR] idx={idx} n={n} dt={dt} M={m} sweeps={sweeps}")
run_id = f"run_{idx:04d}"
base_path = os.environ.get("SDC_OUTPUT_DIR", "/tmp")
variants = []
for prectype in ("MIN-SR-FLEX", "MIN-SR-NS"):
    for is_par in (True, False):
        residual = "par" if is_par else "global"
        group = f"{prectype}_{residual}"
        folder_name = f"{group}/{run_id}"
        params = {
            "n_cells": n,
            "dt": dt,
            "M": m,
            "sweeps": sweeps,
            "Tfinal": TFINAL,
            "degree": DEGREE,
            "is_parallel": is_par,
            "prectype": prectype,
            "analysis": True,
            "mode": "checkpoint",
            "folder_name": folder_name,
            "path_name": base_path,
        }
        variants.append(params)

for v in variants:
    os.environ["SDC_PARAMS_JSON"] = json.dumps(v)
    print("[RUN]", v)
    import runpy
    runpy.run_path("/home/clustor2/ma/o/ok24/clusterscripts/sdc_heat_equation.py", run_name="__main__")
print("[PY] all variants done.")
PY

echo "[COPY] to $DEST"
rsync -av --include='*/' --include='*.h5' --include='*.json' --exclude='*' "$STAGE"/ "$DEST"/ || true
rm -rf "$STAGE" || true

echo "[END] $(date)"